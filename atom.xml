<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://liuwenlu12.github.io/</id>
    <title>刘文路的博客</title>
    <updated>2020-02-26T18:10:18.831Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://liuwenlu12.github.io/"/>
    <link rel="self" href="https://liuwenlu12.github.io//atom.xml"/>
    <subtitle>与其仓皇追赶日落，不如静待漫天星辰</subtitle>
    <logo>https://liuwenlu12.github.io//images/avatar.png</logo>
    <icon>https://liuwenlu12.github.io//favicon.ico</icon>
    <rights>All rights reserved 2020, 刘文路的博客</rights>
    <entry>
        <title type="html"><![CDATA[笔记]]></title>
        <id>https://liuwenlu12.github.io//post/bi-ji</id>
        <link href="https://liuwenlu12.github.io//post/bi-ji">
        </link>
        <updated>2020-02-26T16:08:30.000Z</updated>
        <content type="html"><![CDATA[<p>···<br>
saveAsTable:<br>
1. 如果表不存在, 则会自动创建<br>
2. 如果表存在(append),  则后面存储的数据, 元数据的顺序要与表中的元数据的顺序一致<br>
表内数据:<br>
a(int)     b(string)<br>
新的数据:<br>
aa(int)    bb(string)<br>
3. 列名可以不一致</p>
<p>insertInto<br>
1. 要求表必须存在<br>
2. 要求列名必须一致.<br>
表内数据:<br>
a(int)  b(String)</p>
<pre><code>    新的数据:
        b(string)  a(int)
</code></pre>
<p>···</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ Spark集群启动流程分析]]></title>
        <id>https://liuwenlu12.github.io//post/spark-ji-qun-qi-dong-liu-cheng-fen-xi</id>
        <link href="https://liuwenlu12.github.io//post/spark-ji-qun-qi-dong-liu-cheng-fen-xi">
        </link>
        <updated>2020-02-26T15:53:46.000Z</updated>
        <content type="html"><![CDATA[<h4 id="流程">流程</h4>
<figure data-type="image" tabindex="1"><img src="https://liuwenlu12.github.io//post-images/1582732625980.png" alt=""></figure>
<h4 id="master服务端口-7077">Master服务端口 7077</h4>
<pre><code>   1 val args = new MasterArguments(argStrings, conf)  封装参数

  2  val (rpcEnv, _, _) = startRpcEnvAndEndpoint(args.host, args.port, args.webUiPort, conf)   启动RPC，Endpoint

 3 val rpcEnv = RpcEnv.create(SYSTEM_NAME, host, port, conf, securityMgr) 创建rpcEnv

4     new NettyRpcEnvFactory().create(config) //Netty

5    if (!config.clientMode) //集群模式为true

6           Utils.startServiceOnPort(config.port, startNettyRpcEnv, sparkConf, config.name)._1  启动服务NettyRPCEnv

7           val masterEndpoint = rpcEnv.setupEndpoint(ENDPOINT_NAME,
      new Master(rpcEnv, rpcEnv.address, webUiPort, securityMgr, conf)) 启动Endpoint

8      dispatcher.registerRpcEndpoint(name, endpoint) //注册到dispatcher
            消息分发器 提升异步能力
        
---------------------------------------------
private[spark] trait RpcEnvFactory {
 * An end point for the RPC that defines what functions to trigger given a message.
 *
 * It is guaranteed that `onStart`, `receive` and `onStop` will be called in sequence.
 *
 * The life-cycle of an endpoint is:
 *
 * constructor -&gt; onStart -&gt; receive* -&gt; onStop

* Note: `receive` can be called concurrently. If you want `receive` to be thread-safe, please use
 * [[ThreadSafeRpcEndpoint]]
 *
 * If any error is thrown from one of [[RpcEndpoint]] methods except `onError`, `onError` will be
 * invoked with the cause. If `onError` throws an error, [[RpcEnv]] will ignore it.
---------------------------------------------
 9 onstart --&gt;
 checkForWorkerTimeOutTask = forwardMessageThread.scheduleAtFixedRate//固定检查worker是否超时  默认每分钟一次  自己给自己发消息         self.send(CheckForWorkerTimeOut)
 10 receive--&gt;
  override def receive: PartialFunction[Any, Unit] 
     case CheckForWorkerTimeOut =&gt;
      timeOutDeadWorkers()//移除worker
</code></pre>
<h4 id="worker">Worker</h4>
<pre><code> 1 val args = new WorkerArguments(argStrings, conf)  封装参数
    
 2 val rpcEnv = startRpcEnvAndEndpoint(args.host, args.port, args.webUiPort, args.cores,
      args.memory, args.masters, args.workDir, conf = conf) 启动RPC，Endpoint

  val rpcEnv = RpcEnv.create(systemName, host, port, conf, securityMgr) 创建rpcEnv

 val masterAddresses = masterUrls.map(RpcAddress.fromSparkURL(_))  Mster地址(注册用  高可用有多个  都发送) 

 rpcEnv.setupEndpoint(ENDPOINT_NAME, new Worker(rpcEnv, webUiPort, cores, memory,
      masterAddresses, ENDPOINT_NAME, workDir, conf, securityMgr))   setupEndpoint

3 new Worker--&gt;

def assert(assertion: Boolean) {
    if (!assertion)
      throw new java.lang.AssertionError(&quot;assertion failed&quot;)  已注册抛异常
  }

  4  registerWithMaster()  //注册自己

    registerMasterFutures = tryRegisterAllMasters() //所有master注册

     val masterEndpoint = rpcEnv.setupEndpointRef(masterAddress, Master.ENDPOINT_NAME)
     registerWithMaster(masterEndpoint)
        //获取ref 注册

  masterEndpoint.ask[RegisterWorkerResponse] RegisterWorker(
      workerId, host, port, self, cores, memory, workerWebUiUrl))
 //发信息 希望Mster回一RegisterWorkerResponse  给master自己所有信息

  master端   override def receiveAndReply(context: RpcCallContext): PartialFunction 
     if (state == RecoveryState.STANDBY) {
        context.reply(MasterInStandby)   //自己STANDBY
....各种交互
           5   if (registerWorker(worker)) //Master给与注册

   workers.filter { w =&gt;
      (w.host == worker.host &amp;&amp; w.port == worker.port) &amp;&amp; (w.state == WorkerState.DEAD)
    }.foreach { w =&gt;
      workers -= w
    }   //曾经注册过 状态死  

  context.reply(RegisteredWorker(self, masterWebUiUrl))//响应worker 告诉worker我是哪个master


logInfo(&quot;Successfully registered with master &quot; + masterRef.address.toSparkURL)
      registered = true
     changeMaster(masterRef, masterWebUiUrl) //改地址
forwordMessageScheduler.scheduleAtFixedRate //发心跳

      if (connected) { sendToMaster(Heartbeat(workerId, self)) }  //心跳
      case Some(masterRef) =&gt; masterRef.send(message)

         workerInfo.lastHeartbeat = System.currentTimeMillis() //Master端 一分钟超时  十五秒心跳

master如果没起来   用定时器尝试继续注册自己  16次（6+10）

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spark通讯架构]]></title>
        <id>https://liuwenlu12.github.io//post/spark-tong-xun-jia-gou</id>
        <link href="https://liuwenlu12.github.io//post/spark-tong-xun-jia-gou">
        </link>
        <updated>2020-02-26T15:18:36.000Z</updated>
        <content type="html"><![CDATA[<h4 id="spark-内置-rpc-框架">Spark 内置 RPC 框架</h4>
<p>在 Spark 中, 很多地方都涉及到网络通讯, 比如 Spark 各个组件间的消息互通, 用户文件与 Jar 包的上传, 节点间的 Shuffle 过程, Block 数据的复制与备份等.</p>
<ol>
<li>在 Spark0.x.x 与 Spark1.x.x 版本中, 组件间的消息通信主要借助于 Akka.</li>
<li>在 Spark1.3 中引入了 Netty 通信框架. Akka要求message发送端和接收端有相同的版本, 所以为了避免 Akka 造成的版本问题，并给用户的应用更大灵活性，决定使用更通用的 RPC 实现，也就是现在的 Netty 来替代 Akka。</li>
<li>Spark1.6 中 Akka 和 Netty 可以配置使用。Netty 完全实现了 Akka 在Spark 中的功能。</li>
<li>从Spark2.0.0, Akka 被移除.</li>
</ol>
<h4 id="actor-模型">Actor 模型</h4>
<figure data-type="image" tabindex="1"><img src="https://liuwenlu12.github.io//post-images/1582730544913.png" alt=""></figure>
<h4 id="netty-通信架构">Netty 通信架构</h4>
<p>Netty 借鉴了 Akka 的 Actor 模型<br>
Spark通讯框架中各个组件（Client/Master/Worker）可以认为是一个个独立的实体，各个实体之间通过消息来进行通信。</p>
<figure data-type="image" tabindex="2"><img src="https://liuwenlu12.github.io//post-images/1582730593467.png" alt=""></figure>
<p>详细<br>
<img src="https://liuwenlu12.github.io//post-images/1582730972828.png" alt=""></p>
<p>高层俯视图<br>
<img src="https://liuwenlu12.github.io//post-images/1582731230217.png" alt=""></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spark内核]]></title>
        <id>https://liuwenlu12.github.io//post/spark-nei-he</id>
        <link href="https://liuwenlu12.github.io//post/spark-nei-he">
        </link>
        <updated>2020-02-26T14:43:04.000Z</updated>
        <content type="html"><![CDATA[<h3 id="spark核心组件">Spark核心组件</h3>
<ol>
<li>Cluster Manager (分配的资源属于一级分配, 它将各个 Worker 上的内存, CPU 等资源分配给 Application, 但并不负责对 Executor 的资源的分配)
<ol>
<li>Master  (Standalone)</li>
<li>ResourceManager (Yarn)</li>
<li>MesosMaster (Mesos)</li>
<li>Kubernetes  2.3.0新增 (docker配合)</li>
</ol>
</li>
<li>Worker (工作节点 在 Yarn 部署模式下实际由 NodeManager 替代)
<ol>
<li>将自己的内存, CPU 等资源通过注册机制告知 Cluster Manager</li>
<li>创建 Executor进程</li>
<li>将资源和任务进一步分配给 Executor</li>
<li>同步资源信息, Executor 状态信息给 ClusterManager 等.</li>
</ol>
</li>
<li>Driver (Spark 驱动器节点，用于执行 Spark 任务中的 main 方法，负责实际代码的执行工作)
<ol>
<li>将用户程序转化为作业（Job）；</li>
<li>在 Executor 之间调度任务（Task）；</li>
<li>跟踪 Executor 的执行情况；</li>
<li>通过 UI 展示查询运行情况；</li>
</ol>
</li>
<li>Executor (Spark Executor 节点是负责在 Spark 作业中运行具体任务，任务彼此之间相互独立)        Spark 应用启动时，Executor 节点被同时启动，并且始终伴随着整个 Spark 应用的生命周期而存在。<br>
如果有 Executor 节点发生了故障或崩溃，Spark 应用也可以继续执行，会将出错节点上的任务调度到其他 Executor 节点上继续运行。<br>
Executor 有两个核心功能：</li>
<li>负责运行组成 Spark 应用的任务，并将结果返回给驱动器（Driver）；</li>
<li>它们通过自身的块管理器（Block Manager）为用户程序中要求缓存的 RDD 提供内存式存储。RDD 的数据是直接缓存在 Executor 进程内的，因此任务可以在运行时充分利用缓存数据加速运算。</li>
<li>Application<br>
• Application 通过 Spark API 将进行 RDD 的转换和 DAG 的构建, 并通过 Driver 将 Application 注册到 Cluster Manager.<br>
•	Cluster Manager 将会根据 Application 的资源需求, 通过一级分配将 Executor, 内存, CPU 等资源分配给 Application.<br>
•	Driver 通过二级分配将 Executor 等资源分配给每一个任务, Application 最后通过 Driver 告诉 Executor 运行任务</li>
</ol>
<h5 id="4040端口-driver">4040端口-&gt;Driver</h5>
<h5 id="8080端口-master">8080端口-&gt;Master</h5>
<h5 id="8081端口-worker">8081端口-&gt;Worker</h5>
<h3 id="spark-通用运行流程概述">Spark 通用运行流程概述</h3>
<figure data-type="image" tabindex="1"><img src="https://liuwenlu12.github.io//post-images/1582730179336.png" alt=""></figure>
<ol>
<li>任务提交后，都会先启动 Driver 程序；</li>
<li>随后 Driver 向集群管理器注册应用程序；</li>
<li>之后集群管理器根据此任务的配置文件分配 Executor 并启动该应用程序；</li>
<li>当 Driver 所需的资源全部满足后，Driver 开始执行 main 函数，Spark 转换为懒执行，当执行到 Action 算子时开始反向推算，根据宽依赖进行 Stage 的划分，随后每一个 Stage 对应一个 Taskset，Taskset 中有多个Task；</li>
<li>根据本地化原则，Task 会被分发到指定的 Executor 去执行，在任务执行的过程中，Executor 也会不断与 Driver 进行通信，报告任务运行情况。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[SparkStreaming处理完数据写入redis]]></title>
        <id>https://liuwenlu12.github.io//post/sparkstreaming-chu-li-wan-shu-ju-xie-ru-redis</id>
        <link href="https://liuwenlu12.github.io//post/sparkstreaming-chu-li-wan-shu-ju-xie-ru-redis">
        </link>
        <updated>2020-02-26T14:27:36.000Z</updated>
        <content type="html"><![CDATA[<h4 id="redisutil">RedisUtil</h4>
<pre><code>package com.atguigu.day02.project.util

import redis.clients.jedis.Jedis

object RedisUtil {
  /**
   * 两种方式：
   * 1.使用连接池
   * 效率更高 连接会重用
   * 实际情况 容易出现多线程bug
   * 2.手动创建连接的客户端对象
   * 用完务必关闭
   */
  val host = &quot;lwl007&quot;
  val port = 6379
    //获取客户端对象
  def getClient = new Jedis(host, port)
    //关闭客户端
  def close(client: Jedis): Unit = {
    if (client != null) client.close()
  }
}

</code></pre>
<h4 id="数据写入">数据写入</h4>
<pre><code>    import org.json4s.JsonDSL._ //scala自带转json
    import scala.collection.JavaConversions._ //scala和java集合互转
    val key = &quot;last:hour:ads&quot;
    adsIdAndHmCountIt.foreachRDD(rdd =&gt; {
      rdd.foreachPartition((it: Iterator[(String, Iterable[(String, Int)])]) =&gt; {
        //写入数据
        if (it.hasNext) {
          //建立连接
          val client: Jedis = RedisUtil.getClient
          val map: Map[String, String] = it.map {
            case (adsId, hmCountIt) =&gt; {
              //不加toMap [{},{}]  加toMap{K1:V1,K2:V2}
              val hmCountItToMap: Map[String, Int] = hmCountIt.toMap
              (adsId, JsonMethods.compact(JsonMethods.render(hmCountItToMap)))
            }
          }.toMap
          client.hmset(key, map)
          RedisUtil.close(client)
        }
      })
    })
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[迭代器]]></title>
        <id>https://liuwenlu12.github.io//post/die-dai-qi</id>
        <link href="https://liuwenlu12.github.io//post/die-dai-qi">
        </link>
        <updated>2020-02-26T14:13:40.000Z</updated>
        <content type="html"><![CDATA[<h4 id="他们是一种惰性数据结构并且他们数据只能使用一次">他们是一种惰性数据结构，并且他们数据只能使用一次</h4>
<pre><code> rdd.foreachPartition((it: Iterator[(String, Iterable[(String, Int)])]) =&gt;{
        //建立连接
        val client: Jedis = RedisUtil.getClient
        //写入数据
        //Iterrator
        if(it.size&gt;0){
          println(it.toList)
        }
      })
</code></pre>
<h4 id="结果">结果</h4>
<pre><code>List()
List()
List()
List()
</code></pre>
<h4 id="迭代器独有">迭代器独有</h4>
<pre><code>  if(it.hasNext){  //it.next
          println(it.toList)
        }
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hello Gridea]]></title>
        <id>https://liuwenlu12.github.io//post/hello-gridea</id>
        <link href="https://liuwenlu12.github.io//post/hello-gridea">
        </link>
        <updated>2018-12-11T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
]]></summary>
        <content type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
<!-- more -->
<p><a href="https://github.com/getgridea/gridea">Github</a><br>
<a href="https://gridea.dev/">Gridea 主页</a><br>
<a href="http://fehey.com/">示例网站</a></p>
<h2 id="特性">特性👇</h2>
<p>📝  你可以使用最酷的 <strong>Markdown</strong> 语法，进行快速创作</p>
<p>🌉  你可以给文章配上精美的封面图和在文章任意位置插入图片</p>
<p>🏷️  你可以对文章进行标签分组</p>
<p>📋  你可以自定义菜单，甚至可以创建外部链接菜单</p>
<p>💻  你可以在 <strong>Windows</strong>，<strong>MacOS</strong> 或 <strong>Linux</strong> 设备上使用此客户端</p>
<p>🌎  你可以使用 <strong>𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌</strong> 或 <strong>Coding Pages</strong> 向世界展示，未来将支持更多平台</p>
<p>💬  你可以进行简单的配置，接入 <a href="https://github.com/gitalk/gitalk">Gitalk</a> 或 <a href="https://github.com/SukkaW/DisqusJS">DisqusJS</a> 评论系统</p>
<p>🇬🇧  你可以使用<strong>中文简体</strong>或<strong>英语</strong></p>
<p>🌁  你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力</p>
<p>🖥  你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步</p>
<p>🌱 当然 <strong>Gridea</strong> 还很年轻，有很多不足，但请相信，它会不停向前 🏃</p>
<p>未来，它一定会成为你离不开的伙伴</p>
<p>尽情发挥你的才华吧！</p>
<p>😘 Enjoy~</p>
]]></content>
    </entry>
</feed>