<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Spark 部署模式及源码分析 | 刘文路的博客</title>
<meta name="description" content="与其仓皇追赶日落，不如静待漫天星辰" />
<link rel="shortcut icon" href="https://liuwenlu12.github.io//favicon.ico?v=1582826078259">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
<link rel="stylesheet" href="https://liuwenlu12.github.io//styles/main.css">

<script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://liuwenlu12.github.io/">
  <img class="avatar" src="https://liuwenlu12.github.io//images/avatar.png?v=1582826078259" alt="">
  </a>
  <h1 class="site-title">
    刘文路的博客
  </h1>
  <p class="site-description">
    与其仓皇追赶日落，不如静待漫天星辰
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              Spark 部署模式及源码分析
            </h2>
            <div class="post-info">
              <span>
                2020-02-27
              </span>
              <span>
                7 min read
              </span>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <p>Spark支持3种集群管理器（Cluster Manager），分别为：</p>
<ol>
<li>Standalone：独立模式，Spark 原生的简单集群管理器，自带完整的服务，可单独部署到一个集群中，无需依赖任何其他资源管理系统，使用 Standalone 可以很方便地搭建一个集群；</li>
<li>Hadoop YARN：统一的资源管理机制，在上面可以运行多套计算框架，如 MR、Storm等。根据 Driver 在集群中的位置不同，分为 yarn client 和 yarn cluster；</li>
<li>Apache Mesos：一个强大的分布式资源管理框架，它允许多种不同的框架部署在其上，包括 Yarn。</li>
</ol>
<h3 id="yarn-cluster-模式">YARN Cluster 模式</h3>
<figure data-type="image" tabindex="1"><img src="https://liuwenlu12.github.io//post-images/1582794556881.png" alt=""></figure>
<ol>
<li>执行脚本提交任务，实际是启动一个 SparkSubmit 的 JVM 进程；</li>
<li>SparkSubmit 类中的 main方法反射调用Client的main方法；</li>
<li>Client创建Yarn客户端，然后向Yarn发送执行指令：bin/java ApplicationMaster；</li>
<li>Yarn框架收到指令后会在指定的NM中启动ApplicationMaster；</li>
<li>ApplicationMaster启动Driver线程，执行用户的作业；</li>
<li>AM向RM注册，申请资源；</li>
<li>获取资源后AM向NM发送指令：bin/java CoarseGrainedExecutorBacken；</li>
<li>启动ExecutorBackend, 并向driver注册.</li>
<li>注册成功后, ExecutorBackend会创建一个Executor对象.</li>
<li>Driver会给ExecutorBackend分配任务, 并监控任务的执行.<br>
注意:<br>
•	SparkSubmit、ApplicationMaster和CoarseGrainedExecutorBacken是独立的进程；<br>
•	Client和Driver是独立的线程；<br>
•	Executor是一个对象。</li>
</ol>
<pre><code>cluster: 
bin/spark-submit \                                             
--class org.apache.spark.examples.SparkPi \
--master yarn \
--deploy-mode cluster \
./examples/jars/spark-examples_2.11-2.1.1.jar 1000

-------
SparkSubmit
ApplicationMaster
CoarseGrainedExecutorBackend
--------

SparkSubmit
    org.apache.spark.deploy.SparkSubmit


    if (deployMode == CLIENT || isYarnCluster) {
            // 如果是客户端模式, childMainClass 就是用户的类
            // 集群模式下, childMainClass 被重新赋值为 org.apache.spark.deploy.yarn.Client
            childMainClass = args.mainClass  // 用户主类
            if (isUserJar(args.primaryResource)) {
                childClasspath += args.primaryResource
            }
            if (args.jars != null) {
                childClasspath ++= args.jars.split(&quot;,&quot;)
            }
        }
    if (isYarnCluster) {
            // 在 yarn 集群模式下, 使用yarn.Client来封装一下 user class
            childMainClass = &quot;org.apache.spark.deploy.yarn.Client&quot;
            if (args.isPython) {
                childArgs += (&quot;--primary-py-file&quot;, args.primaryResource)
                childArgs += (&quot;--class&quot;, &quot;org.apache.spark.deploy.PythonRunner&quot;)
            } else if (args.isR) {
                val mainFile = new Path(args.primaryResource).getName
                childArgs += (&quot;--primary-r-file&quot;, mainFile)
                childArgs += (&quot;--class&quot;, &quot;org.apache.spark.deploy.RRunner&quot;)
            } else {
                if (args.primaryResource != SparkLauncher.NO_RESOURCE) {
                    childArgs += (&quot;--jar&quot;, args.primaryResource)
                }
                childArgs += (&quot;--class&quot;, args.mainClass)
            }
            if (args.childArgs != null) {
                args.childArgs.foreach { arg =&gt; childArgs += (&quot;--arg&quot;, arg) }
            }
        }

        childMainClass = &quot;org.apache.spark.deploy.yarn.Client&quot;
            submitApplication()

        // 核心代码: 确定 ApplicationMaster 类
        val amClass =
            if (isClusterMode) { // 如果是 cluster 模式
                Utils.classForName(&quot;org.apache.spark.deploy.yarn.ApplicationMaster&quot;).getName
            } else { // 如果是 client 模式
                Utils.classForName(&quot;org.apache.spark.deploy.yarn.ExecutorLauncher&quot;).getName
            }

        yarnClient.submitApplication(appContext)

        spark-submit进程执行完毕

ApplicationMaster
        runDriver()
        注册AM 让NM要启动的类
        org.apache.spark.executor.CoarseGrainedExecutorBackend

        执行完毕, 但是AM并不会退出,  dirverThread.join()
CoarseGrainedExecutorBackend
        executor进程
        // 获取到 driver 的 RpcEndpointRef  (DriverEndpoint是在sparkContext中创建)
            val driver: RpcEndpointRef = fetcher.setupEndpointRefByURI(driverUrl)

        ref.ask[Boolean](RegisterExecutor(executorId, self, hostname, cores, extractLogUrls))

        driver端:
            executorRef.send(RegisteredExecutor)
        executor端:
            executor = new Executor(executorId, hostname, env, userClassPath, isLocal = false)

</code></pre>
<blockquote>
<p>Cluster 模式概述：脚本在客户端上提交执行，执行SparkSubmit的main方法，会反射一个cilent类，执行client的main方法，然后封装一个指令(bin/java Application)交给RM,RM会选择一台NodeManager启动AM,AM会运行Driver(运行用户类的main方法),同时AM会向RM申请资源和容器,封装并且发送指令,让其他NodeManager启动ExecutorBackend进程,ExecutorBackend进程会向Driver进行反向注册(RegisterExecutor),Driver返回一个成功注册的信息,Executor进程会创建一个Executor对象,之后进行任务分配</p>
</blockquote>
<p>SparkSubmit  Application ExecutorBackend三个进程</p>
<h3 id="yarn-client-模式">Yarn Client 模式</h3>
<figure data-type="image" tabindex="2"><img src="https://liuwenlu12.github.io//post-images/1582800089613.png" alt=""></figure>
<ol>
<li>执行脚本提交任务，实际是启动一个SparkSubmit的 JVM 进程；</li>
<li>SparkSubmit伴生对象中的main方法反射调用用户代码的main方法；</li>
<li>启动Driver线程，执行用户的作业，并创建ScheduleBackend；</li>
<li>YarnClientSchedulerBackend向RM发送指令：bin/java ExecutorLauncher；</li>
<li>Yarn框架收到指令后会在指定的NM中启动ExecutorLauncher（实际上还是调用ApplicationMaster的main方法）；</li>
</ol>
<pre><code>object ExecutorLauncher {
  def main(args: Array[String]): Unit = {
    ApplicationMaster.main(args)
  }
}
</code></pre>
<ol start="6">
<li>AM向RM注册，申请资源；</li>
<li>获取资源后AM向NM发送指令：bin/java CoarseGrainedExecutorBacken；</li>
<li>后面和cluster模式一致<br>
注意：</li>
</ol>
<ul>
<li>SparkSubmit、ExecutorLauncher和CoarseGrainedExecutorBacken是独立的进程；</li>
<li>driver不是一个子线程,而是直接运行在SparkSubmit进程的main线程中, 所以sparkSubmit进程不能退出.</li>
</ul>
<pre><code>bin/spark-submit \                                            
--class org.apache.spark.examples.SparkPi \
--master yarn \
--deploy-mode client \
./examples/jars/spark-examples_2.11-2.1.1.jar 1000

------
SparkSubmit
ExecutorLauncher  (am)
CoarseGrainedExecutorBackend

SparkSubmit
    childMainClass = args.mainClass  // 用户主类

    执行用户类的main方法(执行driver)
        是在SparkSubmit的主线程中执行
        (cluster 模式driver跟着: am, am启动了一个子线程)

    用户类里面, 首先就是在创建和初始化SaprkContext

    SparkContext的初始化:
        val (sched, ts): (SchedulerBackend, TaskScheduler) = SparkContext.createTaskScheduler(this, master, deployMode)
        
        _ts.start()
            backend.start()  
            CoarseGrainedSchedulerBackend: start
                driverEndpoint = createDriverEndpointRef(properties)

            client.submitApplication

                org.apache.spark.deploy.yarn.ExecutorLauncher
                为什么要换个名字：目的是为了区分是运行的client还是cluster模式

            启动DrvierEndPoint
                makeOffers
                    launchTasks(scheduler.resourceOffers(workOffers))

</code></pre>
<blockquote>
<p>Client模式概述：脚本submit提交，脚本启动后，执行SparkSubmit的main方法(同时Driver在SparkSubmit主线程中启动)，Driver的执行会初始化SchedulerBackend, TaskScheduler，YarnCilentSchedulerBackend中有个start方法封装一个bin/java ExcutorLauncher指令交给RM,RM会找一个NodeManager执行ExcutorLauncher(AM),ExcutorLauncher启动后会向RM申请资源，容器. 然后会根据资源和容器去分配NodeManager启动ExcutorBackend进程，向Driver注册(使用RegisterExecutor),返回注册成功之后，创建一个Executor对象，就可以分配任务。</p>
</blockquote>
<h3 id="client模式-和-cluster模式的区别">Client模式 和 Cluster模式的区别</h3>
<pre><code>1. spark-submit中反射childMainClass不同
    cluster:Client    childMainClass = &quot;org.apache.spark.deploy.yarn.Client&quot;
    client:用户类      childMainClass = args.mainClass
2. driver位置
    cluster:位于ApplicationMaster进程中，起一个子线程
    client:位于SparkSubmit的主线程
3. 启动AM
    cluster:ApplicationMaster
    client:ExecutorLauncher

  在cluster模式下，如果AM一旦启动，SparkSubmit还有用吗？   没有用 可以杀掉 一直在打印日志
  在client模式下 ，不能杀  杀了Driver也没了
</code></pre>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li>
<ul>
<li>
<ul>
<li><a href="#yarn-cluster-%E6%A8%A1%E5%BC%8F">YARN Cluster 模式</a></li>
<li><a href="#yarn-client-%E6%A8%A1%E5%BC%8F">Yarn Client 模式</a></li>
<li><a href="#client%E6%A8%A1%E5%BC%8F-%E5%92%8C-cluster%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%8C%BA%E5%88%AB">Client模式 和 Cluster模式的区别</a></li>
</ul>
</li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://liuwenlu12.github.io//post/bi-ji">
              <h3 class="post-title">
                笔记
              </h3>
            </a>
          </div>
        

        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | 
  <a class="rss" href="https://liuwenlu12.github.io//atom.xml" target="_blank">RSS</a>
</div>

<script>
  hljs.initHighlightingOnLoad()

  let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

  // This should probably be throttled.
  // Especially because it triggers during smooth scrolling.
  // https://lodash.com/docs/4.17.10#throttle
  // You could do like...
  // window.addEventListener("scroll", () => {
  //    _.throttle(doThatStuff, 100);
  // });
  // Only not doing it here to keep this Pen dependency-free.

  window.addEventListener("scroll", event => {
    let fromTop = window.scrollY;

    mainNavLinks.forEach((link, index) => {
      let section = document.getElementById(decodeURI(link.hash).substring(1));
      let nextSection = null
      if (mainNavLinks[index + 1]) {
        nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
      }
      if (section.offsetTop <= fromTop) {
        if (nextSection) {
          if (nextSection.offsetTop > fromTop) {
            link.classList.add("current");
          } else {
            link.classList.remove("current");    
          }
        } else {
          link.classList.add("current");
        }
      } else {
        link.classList.remove("current");
      }
    });
  });

</script>

      </div>
    </div>
  </body>
</html>
